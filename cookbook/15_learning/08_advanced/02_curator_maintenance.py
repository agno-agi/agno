"""
Curator Maintenance
==================

Managing and maintaining the curator/learning system over time,
including quality control, cleanup, and optimization.

Key Concepts:
- Memory quality monitoring
- Stale data cleanup
- Conflict resolution
- Performance optimization

Run: python -m cookbook.advanced.02_curator_maintenance
"""



# =============================================================================
# MEMORY QUALITY MONITORING
# =============================================================================


def demo_quality_monitoring():
    """Show how to monitor memory quality."""

    print("=" * 60)
    print("MEMORY QUALITY MONITORING")
    print("=" * 60)

    print("""
    Track these quality metrics:
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 QUALITY DASHBOARD                       â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                         â”‚
    â”‚  USER PROFILES:                                         â”‚
    â”‚  â”œâ”€ Completeness: 78% have >5 facts                     â”‚
    â”‚  â”œâ”€ Freshness: 92% updated in last 30 days              â”‚
    â”‚  â”œâ”€ Conflicts: 12 users with contradictory facts        â”‚
    â”‚  â””â”€ Utilization: 65% of facts used in responses         â”‚
    â”‚                                                         â”‚
    â”‚  ENTITY MEMORY:                                         â”‚
    â”‚  â”œâ”€ Total entities: 15,432                              â”‚
    â”‚  â”œâ”€ Orphaned: 234 (no relationships)                    â”‚
    â”‚  â”œâ”€ Stale: 1,203 (not accessed in 90 days)              â”‚
    â”‚  â””â”€ Duplicates: 45 potential duplicates found           â”‚
    â”‚                                                         â”‚
    â”‚  LEARNED KNOWLEDGE:                                     â”‚
    â”‚  â”œâ”€ Total patterns: 3,567                               â”‚
    â”‚  â”œâ”€ High confidence: 2,890 (81%)                        â”‚
    â”‚  â”œâ”€ Applied recently: 1,234 (35%)                       â”‚
    â”‚  â””â”€ Contradicting: 23 pattern conflicts                 â”‚
    â”‚                                                         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)

    # Example monitoring code
    print("\nğŸ’» MONITORING CODE:")
    print("-" * 40)
    print("""
    async def get_quality_metrics(store):
        '''Collect quality metrics for a learning store.'''
        
        metrics = {
            "total_items": await store.count(),
            "recent_items": await store.count(
                updated_after=datetime.now() - timedelta(days=30)
            ),
            "stale_items": await store.count(
                accessed_before=datetime.now() - timedelta(days=90)
            ),
            "avg_confidence": await store.avg_confidence(),
        }
        
        # Detect potential issues
        metrics["staleness_ratio"] = (
            metrics["stale_items"] / metrics["total_items"]
        )
        metrics["needs_cleanup"] = metrics["staleness_ratio"] > 0.2
        
        return metrics
    """)


# =============================================================================
# STALE DATA CLEANUP
# =============================================================================


def demo_stale_cleanup():
    """Show stale data cleanup patterns."""

    print("\n" + "=" * 60)
    print("STALE DATA CLEANUP")
    print("=" * 60)

    print("""
    Cleanup Strategies:
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚               CLEANUP POLICIES                          â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                         â”‚
    â”‚  SESSION CONTEXT:                                       â”‚
    â”‚  â”œâ”€ Auto-expire after: 7 days                           â”‚
    â”‚  â”œâ”€ Keep if: explicitly bookmarked                      â”‚
    â”‚  â””â”€ Archive to: session_archive table                   â”‚
    â”‚                                                         â”‚
    â”‚  ENTITY MEMORY:                                         â”‚
    â”‚  â”œâ”€ Archive after: 90 days no access                    â”‚
    â”‚  â”œâ”€ Delete after: 365 days in archive                   â”‚
    â”‚  â”œâ”€ Keep if: has active relationships                   â”‚
    â”‚  â””â”€ Merge: duplicate entities automatically             â”‚
    â”‚                                                         â”‚
    â”‚  LEARNED KNOWLEDGE:                                     â”‚
    â”‚  â”œâ”€ Demote after: 180 days no application               â”‚
    â”‚  â”œâ”€ Delete if: confidence drops below 0.3               â”‚
    â”‚  â”œâ”€ Keep if: manually curated                           â”‚
    â”‚  â””â”€ Merge: similar patterns with high overlap           â”‚
    â”‚                                                         â”‚
    â”‚  USER PROFILES:                                         â”‚
    â”‚  â”œâ”€ Retain: indefinitely (core user data)               â”‚
    â”‚  â”œâ”€ Mark stale: facts not confirmed in 180 days         â”‚
    â”‚  â””â”€ Verify: prompt user to confirm stale facts          â”‚
    â”‚                                                         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)

    print("\nğŸ’» CLEANUP IMPLEMENTATION:")
    print("-" * 40)
    print("""
    async def cleanup_stale_data(store, policy):
        '''Run cleanup based on policy.'''
        
        now = datetime.now()
        
        # Find stale items
        stale_items = await store.find(
            accessed_before=now - timedelta(days=policy.stale_days),
            exclude_tags=["pinned", "curated"]
        )
        
        archived = 0
        deleted = 0
        
        for item in stale_items:
            # Check if item has active dependencies
            if await has_active_references(item):
                continue
            
            if item.in_archive:
                # Already archived, check for deletion
                if item.archived_at < now - timedelta(days=policy.delete_days):
                    await store.delete(item.id)
                    deleted += 1
            else:
                # Move to archive
                await store.archive(item.id)
                archived += 1
        
        return {"archived": archived, "deleted": deleted}
    """)


# =============================================================================
# CONFLICT RESOLUTION
# =============================================================================


def demo_conflict_resolution():
    """Show handling conflicting memories."""

    print("\n" + "=" * 60)
    print("CONFLICT RESOLUTION")
    print("=" * 60)

    print("""
    Types of Conflicts:
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚               CONFLICT TYPES                            â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                         â”‚
    â”‚  1. DIRECT CONTRADICTION:                               â”‚
    â”‚     Fact A: "User prefers dark mode"                    â”‚
    â”‚     Fact B: "User prefers light mode"                   â”‚
    â”‚     Resolution: Keep most recent, archive older         â”‚
    â”‚                                                         â”‚
    â”‚  2. PARTIAL OVERLAP:                                    â”‚
    â”‚     Fact A: "User works at Acme Corp"                   â”‚
    â”‚     Fact B: "User is CEO at Acme Corp"                  â”‚
    â”‚     Resolution: Merge into more specific fact           â”‚
    â”‚                                                         â”‚
    â”‚  3. TEMPORAL CHANGE:                                    â”‚
    â”‚     Fact A: "User lives in NYC" (2023)                  â”‚
    â”‚     Fact B: "User lives in LA" (2024)                   â”‚
    â”‚     Resolution: Update with new, note history           â”‚
    â”‚                                                         â”‚
    â”‚  4. CONFIDENCE CONFLICT:                                â”‚
    â”‚     Pattern A: "Always use async" (0.9 confidence)      â”‚
    â”‚     Pattern B: "Sync is fine for simple ops" (0.7)      â”‚
    â”‚     Resolution: Keep both, they're context-dependent    â”‚
    â”‚                                                         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)

    print("\nğŸ’» CONFLICT DETECTION:")
    print("-" * 40)
    print("""
    async def detect_conflicts(user_profile):
        '''Find conflicting facts in user profile.'''
        
        facts = await user_profile.get_all_facts()
        conflicts = []
        
        # Group facts by topic/attribute
        by_attribute = group_by_attribute(facts)
        
        for attr, fact_list in by_attribute.items():
            if len(fact_list) > 1:
                # Multiple facts for same attribute
                conflict = analyze_conflict(fact_list)
                if conflict.is_true_conflict:
                    conflicts.append(conflict)
        
        return conflicts
    
    def resolve_conflict(conflict, strategy="newest_wins"):
        '''Resolve a detected conflict.'''
        
        if strategy == "newest_wins":
            keep = max(conflict.facts, key=lambda f: f.updated_at)
            archive = [f for f in conflict.facts if f != keep]
            return Resolution(keep=keep, archive=archive)
        
        elif strategy == "merge":
            merged = merge_facts(conflict.facts)
            return Resolution(keep=merged, archive=conflict.facts)
        
        elif strategy == "ask_user":
            return Resolution(pending=conflict, needs_user_input=True)
    """)


# =============================================================================
# DUPLICATE DETECTION
# =============================================================================


def demo_duplicate_detection():
    """Show entity deduplication patterns."""

    print("\n" + "=" * 60)
    print("DUPLICATE DETECTION")
    print("=" * 60)

    print("""
    Entity Deduplication:
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚               DUPLICATE EXAMPLES                        â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                         â”‚
    â”‚  Exact Match:                                           â”‚
    â”‚    Entity A: name="John Smith", type="person"           â”‚
    â”‚    Entity B: name="John Smith", type="person"           â”‚
    â”‚    â†’ Merge: combine relationships                       â”‚
    â”‚                                                         â”‚
    â”‚  Fuzzy Match:                                           â”‚
    â”‚    Entity A: name="Acme Corporation"                    â”‚
    â”‚    Entity B: name="Acme Corp"                           â”‚
    â”‚    â†’ Review: likely same, needs confirmation            â”‚
    â”‚                                                         â”‚
    â”‚  Semantic Match:                                        â”‚
    â”‚    Entity A: name="Authentication Service"              â”‚
    â”‚    Entity B: name="Auth Module"                         â”‚
    â”‚    â†’ Context-dependent: may or may not be same          â”‚
    â”‚                                                         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)

    print("\nğŸ’» DEDUPLICATION IMPLEMENTATION:")
    print("-" * 40)
    print("""
    async def find_duplicates(entity_store, threshold=0.85):
        '''Find potential duplicate entities.'''
        
        entities = await entity_store.get_all()
        duplicates = []
        
        for i, entity_a in enumerate(entities):
            for entity_b in entities[i+1:]:
                # Skip different types
                if entity_a.type != entity_b.type:
                    continue
                
                # Calculate similarity
                similarity = calculate_similarity(entity_a, entity_b)
                
                if similarity >= threshold:
                    duplicates.append({
                        "entities": [entity_a, entity_b],
                        "similarity": similarity,
                        "suggested_action": "merge" if similarity > 0.95 else "review"
                    })
        
        return duplicates
    
    async def merge_entities(entity_a, entity_b, keep="newer"):
        '''Merge two entities into one.'''
        
        primary = entity_a if entity_a.updated_at > entity_b.updated_at else entity_b
        secondary = entity_b if primary == entity_a else entity_a
        
        # Merge facts (prefer primary, add unique from secondary)
        merged_facts = primary.facts.copy()
        for fact in secondary.facts:
            if fact not in merged_facts:
                merged_facts.append(fact)
        
        # Merge relationships (combine all)
        merged_relationships = list(set(
            primary.relationships + secondary.relationships
        ))
        
        # Update primary, archive secondary
        await entity_store.update(primary.id, {
            "facts": merged_facts,
            "relationships": merged_relationships,
            "merged_from": [secondary.id]
        })
        await entity_store.archive(secondary.id)
    """)


# =============================================================================
# PERFORMANCE OPTIMIZATION
# =============================================================================


def demo_performance_optimization():
    """Show performance optimization techniques."""

    print("\n" + "=" * 60)
    print("PERFORMANCE OPTIMIZATION")
    print("=" * 60)

    print("""
    Optimization Strategies:
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚             OPTIMIZATION TECHNIQUES                     â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                         â”‚
    â”‚  1. INDEXING:                                           â”‚
    â”‚     â”œâ”€ Index frequently queried fields                  â”‚
    â”‚     â”œâ”€ Use vector indexes for semantic search           â”‚
    â”‚     â””â”€ Partition by namespace for large datasets        â”‚
    â”‚                                                         â”‚
    â”‚  2. CACHING:                                            â”‚
    â”‚     â”œâ”€ Cache user profiles (change rarely)              â”‚
    â”‚     â”œâ”€ Cache recent session context                     â”‚
    â”‚     â””â”€ Cache hot entities per user                      â”‚
    â”‚                                                         â”‚
    â”‚  3. BATCH OPERATIONS:                                   â”‚
    â”‚     â”œâ”€ Batch writes during extraction                   â”‚
    â”‚     â”œâ”€ Bulk index updates                               â”‚
    â”‚     â””â”€ Aggregate metrics calculations                   â”‚
    â”‚                                                         â”‚
    â”‚  4. PRUNING:                                            â”‚
    â”‚     â”œâ”€ Limit retrieved entities per query               â”‚
    â”‚     â”œâ”€ Summarize long session contexts                  â”‚
    â”‚     â””â”€ Archive old learned knowledge                    â”‚
    â”‚                                                         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)

    print("\nğŸ’» CACHING EXAMPLE:")
    print("-" * 40)
    print("""
    class CachedUserProfile:
        '''User profile with caching layer.'''
        
        def __init__(self, store, cache_ttl=300):
            self.store = store
            self.cache = {}
            self.cache_ttl = cache_ttl
        
        async def get(self, user_id):
            # Check cache
            if user_id in self.cache:
                entry = self.cache[user_id]
                if time.time() - entry["time"] < self.cache_ttl:
                    return entry["data"]
            
            # Fetch from store
            data = await self.store.get(user_id)
            
            # Update cache
            self.cache[user_id] = {
                "data": data,
                "time": time.time()
            }
            
            return data
        
        def invalidate(self, user_id):
            '''Call after updates to user profile.'''
            self.cache.pop(user_id, None)
    """)


# =============================================================================
# MAINTENANCE SCHEDULE
# =============================================================================


def demo_maintenance_schedule():
    """Show recommended maintenance schedule."""

    print("\n" + "=" * 60)
    print("MAINTENANCE SCHEDULE")
    print("=" * 60)

    print("""
    Recommended Maintenance Tasks:
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                  DAILY                                  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  â€¢ Clean expired session contexts                       â”‚
    â”‚  â€¢ Process background extraction queue                  â”‚
    â”‚  â€¢ Update search indexes                                â”‚
    â”‚  â€¢ Monitor error rates                                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                  WEEKLY                                 â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  â€¢ Run duplicate detection                              â”‚
    â”‚  â€¢ Archive stale entities                               â”‚
    â”‚  â€¢ Generate quality metrics report                      â”‚
    â”‚  â€¢ Review pending conflict resolutions                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                  MONTHLY                                â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  â€¢ Deep cleanup of archived data                        â”‚
    â”‚  â€¢ Recompute pattern confidence scores                  â”‚
    â”‚  â€¢ Optimize database indexes                            â”‚
    â”‚  â€¢ Review and update extraction prompts                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 QUARTERLY                               â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  â€¢ Full data quality audit                              â”‚
    â”‚  â€¢ Schema migration if needed                           â”‚
    â”‚  â€¢ Performance benchmarking                             â”‚
    â”‚  â€¢ Cost analysis and optimization                       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)


# =============================================================================
# MAIN
# =============================================================================

if __name__ == "__main__":
    print("ğŸ”§ CURATOR MAINTENANCE")
    print("=" * 60)
    print("Managing learning system health over time")
    print()

    demo_quality_monitoring()
    demo_stale_cleanup()
    demo_conflict_resolution()
    demo_duplicate_detection()
    demo_performance_optimization()
    demo_maintenance_schedule()

    print("\n" + "=" * 60)
    print("âœ… Curator maintenance guide complete!")
    print("=" * 60)
