"""Public Team entrypoint.

`Team`'s implementation is split across internal trait modules in
`agno.team.trait.*` to keep this file readable while preserving the public API.
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Callable, Dict, List, Literal, Optional, Type, Union

from pydantic import BaseModel

from agno.agent import Agent
from agno.compression.manager import CompressionManager
from agno.db.base import AsyncBaseDb, BaseDb, ComponentType
from agno.eval.base import BaseEval
from agno.filters import FilterExpr
from agno.guardrails import BaseGuardrail
from agno.knowledge.protocol import KnowledgeProtocol
from agno.memory import MemoryManager
from agno.models.base import Model
from agno.models.message import Message
from agno.registry.registry import Registry
from agno.run.agent import RunEvent
from agno.run.team import TeamRunEvent, TeamRunInput, TeamRunOutput, TeamRunOutputEvent  # noqa: F401
from agno.session import SessionSummaryManager
from agno.team.trait.api import TeamApiTrait
from agno.team.trait.hooks import TeamHooksTrait
from agno.team.trait.init import TeamInitTrait
from agno.team.trait.messages import TeamMessagesTrait
from agno.team.trait.response import TeamResponseTrait
from agno.team.trait.run import TeamRunTrait
from agno.team.trait.storage import TeamStorageTrait
from agno.team.trait.telemetry import TeamTelemetryTrait
from agno.team.trait.tools import TeamToolsTrait
from agno.tools import Toolkit
from agno.tools.function import Function
from agno.utils.log import log_error


@dataclass(init=False)
class Team(
    TeamInitTrait,  # Initialization, configuration, and member wiring
    TeamRunTrait,  # Core run loop (sync/async) + streaming lifecycle
    TeamHooksTrait,  # Pre/post-run hooks + model stream update handlers
    TeamToolsTrait,  # Tool registration, member delegation, and knowledge tools
    TeamStorageTrait,  # Session/config persistence + serialization helpers
    TeamMessagesTrait,  # Prompt/message construction and deep-copy helpers
    TeamResponseTrait,  # Structured response parsing and reasoning helpers
    TeamApiTrait,  # Convenience APIs (print_response, cli_app, cleanup)
    TeamTelemetryTrait,  # Telemetry payload generation and logging
):
    """Team: The orchestrator for multiple agents and/or nested teams.

    Composed from modular internal traits. Trait order is intentional: if two
    traits define the same method name, Python's MRO gives precedence to traits
    listed earlier.
    """

    members: List[Union[Agent, "Team"]]

    # Model for this Team
    model: Optional[Model] = None

    # --- Team settings ---
    # Team UUID (autogenerated if not set)
    id: Optional[str] = None
    # Name of the team
    name: Optional[str] = None
    # If this team is part of a team itself, this is the role of the team
    role: Optional[str] = None

    # --- If this Team is part of a team itself ---
    # If this team is part of a team itself, this is the ID of the parent team. This is set automatically.
    parent_team_id: Optional[str] = None

    # --- If this Team is part of a workflow ---
    # Optional workflow ID. Indicates this team is part of a workflow. This is set automatically.
    workflow_id: Optional[str] = None

    # --- Team execution settings ---
    # If True, the team leader won't process responses from the members and instead will return them directly
    # Should not be used in combination with delegate_to_all_members
    respond_directly: bool = False
    # If True, the team leader will delegate the task to all members, instead of deciding for a subset
    delegate_to_all_members: bool = False
    # Set to false if you want to send the run input directly to the member agents
    determine_input_for_members: bool = True

    # --- User settings ---
    # Default user ID for this team
    user_id: Optional[str] = None

    # --- Session settings ---
    # Default Session ID for this team (autogenerated if not set)
    session_id: Optional[str] = None
    # Session state (stored in the database to persist across runs)
    session_state: Optional[Dict[str, Any]] = None
    # Set to True to add the session_state to the context
    add_session_state_to_context: bool = False
    # Set to True to give the team tools to update the session_state dynamically
    enable_agentic_state: bool = False
    # Set to True to overwrite the stored session_state with the session_state provided in the run
    overwrite_db_session_state: bool = False
    # If True, cache the current Team session in memory for faster access
    cache_session: bool = False

    # Add this flag to control if the workflow should send the team history to the members. This means sending the team-level history to the members, not the agent-level history.
    add_team_history_to_members: bool = False
    # Number of historical runs to include in the messages sent to the members
    num_team_history_runs: int = 3
    # If True, send all member interactions (request/response) during the current run to members that have been delegated a task to
    share_member_interactions: bool = False

    # If True, adds a tool to allow searching through previous sessions
    search_session_history: Optional[bool] = False
    # Number of past sessions to include in the search
    num_history_sessions: Optional[int] = None

    # If True, adds a tool to allow the team to read the chat history
    read_chat_history: bool = False

    # --- System message settings ---
    # A description of the Team that is added to the start of the system message.
    description: Optional[str] = None
    # List of instructions for the team.
    instructions: Optional[Union[str, List[str], Callable]] = None
    # If True, wrap instructions in <instructions> tags. Default is False.
    use_instruction_tags: bool = False
    # Provide the expected output from the Team.
    expected_output: Optional[str] = None
    # Additional context added to the end of the system message.
    additional_context: Optional[str] = None
    # If markdown=true, add instructions to format the output using markdown
    markdown: bool = False
    # If True, add the current datetime to the instructions to give the team a sense of time
    # This allows for relative times like "tomorrow" to be used in the prompt
    add_datetime_to_context: bool = False
    # If True, add the current location to the instructions to give the team a sense of location
    add_location_to_context: bool = False
    # Allows for custom timezone for datetime instructions following the TZ Database format (e.g. "Etc/UTC")
    timezone_identifier: Optional[str] = None
    # If True, add the team name to the instructions
    add_name_to_context: bool = False
    # If True, add the tools available to team members to the context
    add_member_tools_to_context: bool = False

    # Provide the system message as a string or function
    system_message: Optional[Union[str, Callable, Message]] = None
    # Role for the system message
    system_message_role: str = "system"
    # Introduction for the team
    introduction: Optional[str] = None

    # If True, resolve the session_state, dependencies, and metadata in the user and system messages
    resolve_in_context: bool = True

    # --- Extra Messages ---
    # A list of extra messages added after the system message and before the user message.
    # Use these for few-shot learning or to provide additional context to the Model.
    # Note: these are not retained in memory, they are added directly to the messages sent to the model.
    additional_input: Optional[List[Union[str, Dict, BaseModel, Message]]] = None

    # --- Database ---
    # Database to use for this agent
    db: Optional[Union[BaseDb, AsyncBaseDb]] = None

    # Memory manager to use for this agent
    memory_manager: Optional[MemoryManager] = None

    # --- User provided dependencies ---
    # User provided dependencies
    dependencies: Optional[Dict[str, Any]] = None
    # If True, add the dependencies to the user prompt
    add_dependencies_to_context: bool = False

    # --- Agent Knowledge ---
    knowledge: Optional[KnowledgeProtocol] = None
    # Add knowledge_filters to the Agent class attributes
    knowledge_filters: Optional[Union[Dict[str, Any], List[FilterExpr]]] = None
    # Let the agent choose the knowledge filters
    enable_agentic_knowledge_filters: Optional[bool] = False
    # Add a tool that allows the Team to update Knowledge.
    update_knowledge: bool = False
    # If True, add references to the user prompt
    add_knowledge_to_context: bool = False
    # Retrieval function to get references
    # This function, if provided, is used instead of the default search_knowledge function
    # Signature:
    # def knowledge_retriever(team: Team, query: str, num_documents: Optional[int], **kwargs) -> Optional[list[dict]]:
    #     ...
    knowledge_retriever: Optional[Callable[..., Optional[List[Union[Dict, str]]]]] = None
    references_format: Literal["json", "yaml"] = "json"

    # --- Tools ---
    # If True, add a tool to get information about the team members
    get_member_information_tool: bool = False
    # Add a tool to search the knowledge base (aka Agentic RAG)
    # Only added if knowledge is provided.
    search_knowledge: bool = True
    # If True, add search_knowledge instructions to the system prompt
    add_search_knowledge_instructions: bool = True

    # If False, media (images, videos, audio, files) is only available to tools and not sent to the LLM
    send_media_to_model: bool = True
    # If True, store media in run output
    store_media: bool = True
    # If True, store tool results in run output
    store_tool_messages: bool = True
    # If True, store history messages in run output
    store_history_messages: bool = True

    # --- Team Tools ---
    # A list of tools provided to the Model.
    # Tools are functions the model may generate JSON inputs for.
    tools: Optional[List[Union[Toolkit, Callable, Function, Dict]]] = None

    # Controls which (if any) tool is called by the team model.
    # "none" means the model will not call a tool and instead generates a message.
    # "auto" means the model can pick between generating a message or calling a tool.
    # Specifying a particular function via {"type: "function", "function": {"name": "my_function"}}
    #   forces the model to call that tool.
    # "none" is the default when no tools are present. "auto" is the default if tools are present.
    tool_choice: Optional[Union[str, Dict[str, Any]]] = None
    # Maximum number of tool calls allowed.
    tool_call_limit: Optional[int] = None
    # A list of hooks to be called before and after the tool call
    tool_hooks: Optional[List[Callable]] = None

    # --- Team Hooks ---
    # Functions called right after team session is loaded, before processing starts
    pre_hooks: Optional[List[Union[Callable[..., Any], BaseGuardrail, BaseEval]]] = None
    # Functions called after output is generated but before the response is returned
    post_hooks: Optional[List[Union[Callable[..., Any], BaseGuardrail, BaseEval]]] = None
    # If True, run hooks as FastAPI background tasks (non-blocking). Set by AgentOS.
    _run_hooks_in_background: Optional[bool] = None

    # --- Structured output ---
    # Input schema for validating input
    input_schema: Optional[Type[BaseModel]] = None
    # Provide a response model to get the response in the implied format.
    # You can use a Pydantic model or a JSON fitting the provider's expected schema.
    output_schema: Optional[Union[Type[BaseModel], Dict[str, Any]]] = None
    # Provide a secondary model to parse the response from the primary model
    parser_model: Optional[Model] = None
    # Provide a prompt for the parser model
    parser_model_prompt: Optional[str] = None
    # Provide an output model to parse the response from the team
    output_model: Optional[Model] = None
    # Provide a prompt for the output model
    output_model_prompt: Optional[str] = None
    # Intead of providing the model with the Pydantic output schema, add a JSON description of the output schema to the system message instead.
    use_json_mode: bool = False
    # If True, parse the response
    parse_response: bool = True

    # --- History ---
    # Enable the agent to manage memories of the user
    enable_agentic_memory: bool = False
    # If True, the agent creates/updates user memories at the end of runs
    update_memory_on_run: bool = False
    # Soon to be deprecated. Use update_memory_on_run
    enable_user_memories: Optional[bool] = None
    # If True, the agent adds a reference to the user memories in the response
    add_memories_to_context: Optional[bool] = None
    # If True, the agent creates/updates session summaries at the end of runs
    enable_session_summaries: bool = False
    # # Session summary model
    # session_summary_model: Optional[Model] = None
    # # Session summary prompt
    # session_summary_prompt: Optional[str] = None
    session_summary_manager: Optional[SessionSummaryManager] = None
    # If True, the team adds session summaries to the context
    add_session_summary_to_context: Optional[bool] = None

    # --- Context Compression ---
    # If True, compress tool call results to save context
    compress_tool_results: bool = False
    # Compression manager for compressing tool call results
    compression_manager: Optional["CompressionManager"] = None

    # --- Team History ---
    # add_history_to_context=true adds messages from the chat history to the messages list sent to the Model.
    add_history_to_context: bool = False
    # Number of historical runs to include in the messages
    num_history_runs: Optional[int] = None
    # Number of historical messages to include in the messages list sent to the Model.
    num_history_messages: Optional[int] = None
    # Maximum number of tool calls to include from history (None = no limit)
    max_tool_calls_from_history: Optional[int] = None

    # --- Team Storage ---
    # Metadata stored with this team
    metadata: Optional[Dict[str, Any]] = None
    # Version of the team config (set when loaded from DB)
    version: Optional[int] = None

    # --- Team Reasoning ---
    reasoning: bool = False
    reasoning_model: Optional[Model] = None
    reasoning_agent: Optional[Agent] = None
    reasoning_min_steps: int = 1
    reasoning_max_steps: int = 10

    # --- Team Streaming ---
    # Stream the response from the Team
    stream: Optional[bool] = None
    # Stream the intermediate steps from the Agent
    stream_events: Optional[bool] = None
    # Stream the member events from the Team
    stream_member_events: bool = True

    # Store the events from the Team
    store_events: bool = False
    # List of events to skip from the Team
    events_to_skip: Optional[List[Union[RunEvent, TeamRunEvent]]] = None
    # Store member agent runs inside the team's RunOutput
    store_member_responses: bool = False

    # --- Debug ---
    # Enable debug logs
    debug_mode: bool = False
    # Debug level: 1 = basic, 2 = detailed
    debug_level: Literal[1, 2] = 1
    # Enable member logs - Sets the debug_mode for team and members
    show_members_responses: bool = False

    # --- Team Response Settings ---
    # Number of retries to attempt
    retries: int = 0
    # Delay between retries (in seconds)
    delay_between_retries: int = 1
    # Exponential backoff: if True, the delay between retries is doubled each time
    exponential_backoff: bool = False

    # --- Telemetry ---
    # telemetry=True logs minimal telemetry for analytics
    # This helps us improve the Teams implementation and provide better support
    telemetry: bool = True


def get_team_by_id(
    db: "BaseDb",
    id: str,
    version: Optional[int] = None,
    label: Optional[str] = None,
    registry: Optional["Registry"] = None,
) -> Optional["Team"]:
    """
    Get a Team by id from the database.

    Resolution order:
    - if version is provided: load that version
    - elif label is provided: load that labeled version
    - else: load component.current_version

    Args:
        db: Database handle.
        id: Team component_id.
        version: Optional integer config version.
        label: Optional version_label.
        registry: Optional Registry for reconstructing unserializable components.

    Returns:
        Team instance or None.
    """
    try:
        row = db.get_config(component_id=id, version=version, label=label)
        if row is None:
            return None

        cfg = row.get("config") if isinstance(row, dict) else None
        if cfg is None:
            raise ValueError(f"Invalid config found for team {id}")

        team = Team.from_dict(cfg, db=db, registry=registry)
        # Ensure team.id is set to the component_id
        team.id = id

        return team

    except Exception as e:
        log_error(f"Error loading Team {id} from database: {e}")
        return None


def get_teams(
    db: "BaseDb",
    registry: Optional["Registry"] = None,
) -> List["Team"]:
    """
    Get all teams from the database.

    Args:
        db: Database to load teams from
        registry: Optional registry for rehydrating tools

    Returns:
        List of Team instances loaded from the database
    """
    teams: List[Team] = []
    try:
        components, _ = db.list_components(component_type=ComponentType.TEAM)
        for component in components:
            component_id = component["component_id"]
            config = db.get_config(component_id=component_id)
            if config is not None:
                team_config = config.get("config")
                if team_config is not None:
                    if "id" not in team_config:
                        team_config["id"] = component_id
                    team = Team.from_dict(team_config, db=db, registry=registry)
                    # Ensure team.id is set to the component_id
                    team.id = component_id
                    teams.append(team)
        return teams

    except Exception as e:
        log_error(f"Error loading Teams from database: {e}")
        return []
