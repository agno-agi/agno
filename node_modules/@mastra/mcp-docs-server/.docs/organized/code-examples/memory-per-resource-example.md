### package.json
```json
{
  "name": "memory-per-resource-example",
  "dependencies": {
    "@ai-sdk/openai": "^1.3.24",
    "@mastra/core": "latest",
    "@mastra/memory": "latest",
    "@mastra/libsql": "latest",
    "chalk": "^5.3.0",
    "dotenv": "^16.4.7",
    "ora": "^8.1.1",
    "tsx": "^4.19.2"
  },
  "devDependencies": {
    "@types/node": "^20.19.0",
    "typescript": "^5.8.3"
  }
}
```

### example.ts
```typescript
import { maskStreamTags } from '@mastra/core/utils';
import chalk from 'chalk';
import { randomUUID } from 'crypto';
import ora from 'ora';
import Readline from 'readline';

import 'dotenv/config';

import { mastra } from './mastra';

const agent = mastra.getAgent('assistantAgent');

// ðŸ†• EXAMPLE: Per-Resource Working Memory
// This demonstrates how working memory persists across different conversation threads
// for the same user (resourceId), but is separate for different users.

console.log(chalk.bold.blue('\nðŸ†• Per-Resource Working Memory Example\n'));
console.log(chalk.gray('This example shows how working memory persists across conversation threads'));
console.log(chalk.gray('for the same user, but stays separate for different users.\n'));

// Simulate different users
const USERS = {
  alice: 'user-alice-123',
  bob: 'user-bob-456',
  demo: 'demo-user-789',
};

// Let user choose which user to simulate
console.log(chalk.yellow('Choose a user to simulate:'));
console.log(chalk.cyan('1. Alice (user-alice-123)'));
console.log(chalk.cyan('2. Bob (user-bob-456)'));
console.log(chalk.cyan('3. Demo User (demo-user-789)'));
console.log(chalk.gray('4. Or just press Enter to use a random user\n'));

const rl = Readline.createInterface({
  input: process.stdin,
  output: process.stdout,
});

const userChoice = await new Promise<string>(resolve => {
  rl.question(chalk.yellow('Enter choice (1-4 or Enter): '), answer => {
    resolve(answer.trim());
  });
});

let resource: string;
let userName: string;

switch (userChoice) {
  case '1':
    resource = USERS.alice;
    userName = 'Alice';
    break;
  case '2':
    resource = USERS.bob;
    userName = 'Bob';
    break;
  case '3':
    resource = USERS.demo;
    userName = 'Demo User';
    break;
  default:
    resource = `user-${randomUUID()}`;
    userName = 'Random User';
}

// Always generate a new thread ID to demonstrate cross-thread persistence
const thread = randomUUID();

console.log(chalk.green(`\nâœ… Simulating: ${userName}`));
console.log(chalk.gray(`ðŸ“§ Resource ID: ${resource}`));
console.log(chalk.gray(`ðŸ§µ Thread ID: ${thread}`));
console.log(chalk.bold.yellow('\nðŸ’¡ TIP: Run this example multiple times with the same user choice'));
console.log(chalk.bold.yellow('   to see how working memory persists across conversation threads!\n'));

async function logResponse(res: Awaited<ReturnType<typeof agent.stream>>) {
  console.log(chalk.blue('\nðŸ¤– Assistant:'));

  const memorySpinner = ora('ðŸ’¾ Updating memory...');

  // Mask working memory updates with a spinner
  const maskedStream = maskStreamTags(res.textStream, 'working_memory', {
    onStart: () => memorySpinner.start(),
    onEnd: () => {
      if (memorySpinner.isSpinning) {
        memorySpinner.succeed(chalk.green('ðŸ’¾ Memory updated!'));
      }
    },
  });

  for await (const chunk of maskedStream) {
    process.stdout.write(chunk);
  }
  console.log('\n');
}

async function main() {
  // Start the conversation
  await logResponse(
    await agent.stream(
      [
        {
          role: 'system',
          content: `New conversation thread started at ${new Date().toISOString()}. 
        This may be a returning user - check your working memory to see if you know them already.
        If this is a new user, introduce yourself and learn about them.
        If this is a returning user, greet them warmly and reference what you remember!`,
        },
      ],
      { memory: { thread, resource } },
    ),
  );

  // Interactive chat loop
  while (true) {
    const userInput: string = await new Promise(resolve => {
      rl.question(chalk.yellow('\nðŸ’¬ You: '), answer => {
        resolve(answer);
      });
    });

    if (userInput.toLowerCase() === 'exit' || userInput.toLowerCase() === 'quit') {
      console.log(chalk.gray('\nðŸ‘‹ Goodbye! Run the example again to see memory persistence!\n'));
      break;
    }

    await logResponse(await agent.stream(userInput, { memory: { thread, resource } }));
  }

  rl.close();
}

main().catch(console.error);

```

### mastra/agents/index.ts
```typescript
import { openai } from '@ai-sdk/openai';
import { Agent } from '@mastra/core/agent';
import { Memory } from '@mastra/memory';
import { LibSQLStore } from '@mastra/libsql';

// Create LibSQL storage for persistent per-resource working memory
const storage = new LibSQLStore({
  url: 'file:./memory-demo.db',
});

export const memory = new Memory({
  storage,
  options: {
    lastMessages: 5,
    workingMemory: {
      enabled: true,
      scope: 'resource', // ðŸ†• NEW: Per-resource working memory!
      template: `# User Profile
- **Name**: 
- **Location**: 
- **Interests**: 
- **Preferences**: 
- **Goals**: 
- **Important Notes**: 
`,
    },
  },
});

export const assistantAgent = new Agent({
  name: 'Personal Assistant',
  instructions: `You are a helpful personal assistant with persistent memory across ALL conversations.

ðŸ†• IMPORTANT: You have resource-scoped working memory! This means:
- Everything you learn about this user persists across ALL conversation threads
- Even if they start a completely new conversation, you'll remember them
- You should build up a comprehensive profile of the user over time

Always use <working_memory> tags to update what you know about the user:
- Their name and personal details
- Their interests and preferences  
- Their goals and what they're working on
- Any important context from previous conversations

When you first meet someone, ask for their name and learn about them. In subsequent conversations (even new threads), greet them by name and reference what you remember!`,
  model: openai('gpt-4o-mini'),
  memory,
});

```

### mastra/index.ts
```typescript
import { Mastra } from '@mastra/core';
import { assistantAgent } from './agents';

export const mastra = new Mastra({
  agents: { assistantAgent },
});

```
