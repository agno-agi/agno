# Problem statement

Our current implementation of teams is very narrow:

1. Teams only work in one way: you create a few agents with specific goals, you add them to the `team` of a team leader agent, and the team leader agent has the ability to transfer a task to a team member.
    1. This way is restrictive, because the team leader “makes up” a task description to best coordinate for the larger goal.
    2. Sometimes users want a team-leader that just proxies the user prompt to the appropriate agent.
    3. The current “transfer function” does not support all of the multimodal parameters sent to the `run` of the team leader agent.
2. Since team leaders and team members are instances of `Agent` , so the assumption is that everything that works on an agent should work in a team setup.
    1. Attributes like knowledge, memory, etc set on a team-leader does not propagate to member agents
    2. Team leader and team members should ideally share a session ID, this is not the case. Their sessions/runs are seen as independent.
    3. Structured outputs from team members are not used or returned.
3. The current team leader has a large and static system message that contributes a great deal to the context. There is no flexibility.
4. Responses from team members are added to the team-leader’s context, which can blow up their context when history is also enabled. Team leaders should ideally be able to have flexibility on how many of the team member’s responses to keep.

# Real Use Cases

1. Autonomous Startup Founder Team → [Autonomous Startup Founder Team](https://www.notion.so/Autonomous-Startup-Founder-Team-1a5733793ba2802dbc21cee0ed05bff7?pvs=21) 
2. A financial analysis team → [Financial Research Team](https://www.notion.so/Financial-Research-Team-1a5733793ba280ea9317fb8810ed472f?pvs=21) 
3. AI customer support → [AI Customer Support System](https://www.notion.so/AI-Customer-Support-System-1a5733793ba28061b2e3cdccc9d87783?pvs=21) 
4. Rap battle between models → [Rap Battle between Models](https://www.notion.so/Rap-Battle-between-Models-1a5733793ba2806386f1cf299486c229?pvs=21) 
5. LLM OS: A large team of agents, each with a designated role and a few tools. The team leader themself also has several tools. 

[Use Cases for Agent Teams](https://www.notion.so/Use-Cases-for-Agent-Teams-1a5733793ba28040b86fced5969b3564?pvs=21) 

# Proposed Team Concepts:

- A “Team” is a new concept we introduce on the same level as “Agent” and “Workflow”.
- A Team has an internal agent that acts as the leader of the team.
- The team will be in a mode. Either “coordinator”, “router”, or “collaborative”.
    - When in “coordinator” mode, transfers tasks intelligently to team members (like what we have now).
    - When in “router” mode, decides which member agent (mostly singular) is best suited for the task at hand. It then forwards the prompt as-is and returns the response from the member agent as-is. There will be no difference between the response of the team and the response of the member itself.
    - When in “collaborative” mode, the leader agent sends the same task to each member agent in round robin (sync) or concurrently (async) and gets all the responses before responding.
- When in “coordinator” and “collaborative” mode, the leader agent should selectively add to the context of member agents given the larger context of responses from other member agents. This will also allow it to output from one member agent to be available to other member agents, selectively.
- Team members should be regular agents with all the capabilities of a normal agent
- Team members should possibly also be “teams” themselves. There could be a use-case for a proxy leader with some normal members and a coordinator that would solve sub-tasks.
- When enabling “history”, “storage”, or “memory” on a team level, it should automatically apply to team members if it is not set.
- Team members should be able to have their own history implementation. This will be separate from that of the team leader and the team leader can selectively send context.

# UI Considerations

- We want to have `agents`, `teams`, and `workflows` as concepts on the Agno platform.

# API Considerations:

[APIs](https://www.notion.so/APIs-1ac733793ba28083b53bea5d8726c237?pvs=21)

# Proposed Solution

- We create `Team` object with the following structure:

```python
class Team:
	members: List[Agent, Team] # Can be teams within team
	mode: Literal["coordinator", "router", "collaborative"] = "coordinator"
	model: OpenAIChat()  # Model used for the team-leader agent
	
	description: Optional[str]
	instuctions: Optional[Union[str, List[str], Callable]]
	success_criteria: Optional[str] # Define what would make the team successful in their requests
	expected_output: Optional[str]
	add_datetime_to_instructions: bool = False

	user_id: Optional[str]
	session_id: Optional[str]
	session_name: Optional[str]
	session_state: Optional[Dict[str, Any]]
  add_state_in_messages: bool = False
	
	# Custom tools
	send_team_context_to_members: bool # See below
	select_team_context_to_send_to_members: bool # See below
	update_team_context: bool # See Below
	
	
	# User provided context
  context: Optional[Dict[str, Any]]
  add_context: bool = False
  resolve_context: bool = True
	
	memory: Optional[TeamMemory]       # Used for member context and leader memory
	enable_team_history: bool = False # This means all leader request and response will go to the leader's history (not member request/response).
	num_of_interactions_from_history: int = 3 # The full series of interactions, instead of individual messages as with agent
  num_of_messages_from_history: Optional[int] # Individual model messages, for more control
  max_history_tokens: Optional[int]
	read_team_history: bool = False
	
	storage: Optional[AgentStorage]
	extra_data: Optional[Dict[str, Any]]
	
	response_model: Type[BaseModel]  # Individual member agents can still have their own response_model
  json_response_mode: bool = False # As opposed to `structured_output=False`. I think this is a better DX
  parse_response: bool = True
  save_response_to_file: Optional[str] = None
  
  # The reasoning model will be used at the start of every round and will reason about the task(s)
  reasoning: bool = False
  reasoning_model: Optional[Model] = None
  
  # The team can be given a list of tasks to complete. The team will go in rounds until all the tasks are completed.
  # A single prompt will count as a single task (or override the set tasks)
  tasks: Optional[List[str]] = None
  
  max_rounds: int = 3 # Maximum number of iterations that the team leader has to complete a task
  
  debug_mode: bool = False # If true, would set to true for all members as well
  show_member_responses: bool = False # Shows separate blocks for member responses in `print_response` 
  monitoring: bool = False # If true, would set to true for all members as well
  telemetry: bool = True # If true, would set to true for all members as well
  
  def run(
    self,
    message: Optional[Union[str, List, Dict, Message]] = None,
    *,
    stream: Literal[False] = False,
    audio: Optional[Sequence[Audio]] = None,
    images: Optional[Sequence[Image]] = None,
    videos: Optional[Sequence[Video]] = None,
    retries: Optional[int] = None,
    tasks: Optional[List[str]] = None  # Can also be specified on runs
    **kwargs: Any,
) -> RunResponse: ...
```

- We won’t (yet) support `knowledge`
- We won’t support `tools` on the `Team`
- The leader agent will maintain a single `TeamRunResponse` and will append `images` , `audio`, `video` as might be generated by team members, and this will be in the final response. Also a list of `team_responses: List[RunResponse]` that contains the responses of the team members.
- In the case of `mode="coordinator"`
    
    ![Screenshot 2025-03-02 at 22.13.48.png](attachment:1a8e5627-c4a3-498f-ab58-23d96f87e53e:Screenshot_2025-03-02_at_22.13.48.png)
    
    ![Screenshot 2025-03-02 at 22.11.16.png](attachment:2aa067ec-3856-4ac5-974d-b2e32c953537:Screenshot_2025-03-02_at_22.11.16.png)
    
    - Make the system message
        
        ```python
        "<agent_team>\n"
          "You are the leader of a team of AI Agents:\n"
          "  - Agent 1: \n"
        	"    - Name: xxx with role yyy\n"
        	"    - Tools: \n"
        	"       - tool_1: description\n"
        	"       - tool_2: description\n"
          "  - Agent 2: \n"
        	"    - Name: xxx with role yyy\n"
        	"    - Tools: \n"
        	"       - tool_1: description\n"
        	"       - tool_2: description\n"
          "- You can either respond directly or transfer tasks to member agents in your team depending on the tools available to them.\n"
          "- You must always validate the output of the other Agents before responding to the user.\n"
          "- You can re-assign the task if you are not satisfied with the result.\n"
          "</agent_team>\n\n"
        ```
        
    - The team leader agent will execute iterations of `transfer_task_to_agent` until it is satisfied that the request has been solved. In the case of `tasks` it would iterate until all the tasks has been resolved. If run `async`, the iterations of `transfer_task_to_agent` in a single round will be executed concurrently.
    - Instead of having `n` transfer functions for `n` agents, there will be a single `transfer_task_to_agent` which takes `agent_name: str`, `task_description:str` , `expected_output: str` (we’ll remove `additional_information`), and `team_context`, and calls the `run` or `arun` of the correct agent. The appropriate `team_context` will be passed to the member agents. Structured responses will be processed correctly from member agents and stored in `team_context`.
    - The `memory` of the `Team` will be updated with calls to `transfer_task_to_agent` and the subsequent responses. Stored in `team_context`
    - If `update_team_context=True`, the leader will get a function `_set_team_context` to set a shared text-blob that will be added to the team context.
    - `send_context_to_members: bool` → By default the entire `team_context` will be sent to each member agent.
    - `select_context_to_send_to_members: bool` → The agent will receive the whole `team_context` before making the `transfer_task_to_agent` request, and then selectively send specific request/response from members as it makes sense to the leader.
- In the case of `mode="router"`
    
    ![Screenshot 2025-03-02 at 22.21.37.png](attachment:a8558607-369a-4fba-b496-4d895133d156:Screenshot_2025-03-02_at_22.21.37.png)
    
    ![Screenshot 2025-03-02 at 22.21.56.png](attachment:601468ea-16da-41d4-9227-4856b3de1e55:Screenshot_2025-03-02_at_22.21.56.png)
    
    - Make the system message
        
        ```python
        "<agent_team>\n"
          "You are the leader of a team of AI Agents:\n"
          "  - Agent 1: \n"
        	"    - Name: xxx with role yyy\n"
        	"    - Tools: \n"
        	"       - tool_1: description\n"
        	"       - tool_2: description\n"
          "  - Agent 2: \n"
        	"    - Name: xxx with role yyy\n"
        	"    - Tools: \n"
        	"       - tool_1: description\n"
        	"       - tool_2: description\n"
          "- You must decide which agent is best suited for the task given to you, then forward the request to that agent.\n"
          "</agent_team>\n\n"
        ```
        
    - Provide a single tool `forward_task_to_agent` which takes `agent_name` and calls the `run` or `arun` of the correct agent with the message provided to the team agent (including images, audio, videos and other settings).
    - Return the response from the member agent as the `TeamRunResponse`
- In the case of `mode="collaborative"`
    
    ![Screenshot 2025-03-02 at 22.23.46.png](attachment:bf4d1aeb-70a4-4473-841b-7e5137bfd18e:Screenshot_2025-03-02_at_22.23.46.png)
    
    ![Screenshot 2025-03-02 at 22.26.15.png](attachment:da52a3e2-1f7c-40ee-a153-873c84d4d32c:Screenshot_2025-03-02_at_22.26.15.png)
    
    - The member agents are all given the same task, in a round-robin fashion.
    - The leader agent uses the `success_criteria` and the prompt to determine when it should stop the round-robin discussion.